{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12361529,"sourceType":"datasetVersion","datasetId":7793720},{"sourceId":12390885,"sourceType":"datasetVersion","datasetId":7813419},{"sourceId":457363,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":370874,"modelId":391773}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-17T06:16:42.103107Z","iopub.execute_input":"2025-07-17T06:16:42.103270Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/netra_dyne/pytorch/default/1/best 1.pt\n/kaggle/input/netra-jpeg/JPEGImages_200/e8b51f33b7d38c96f51a97651db0ed2677861cf1_000003.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/8b7006f219a6608b100190d77760c6a48dad7031_000020.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/e9dcd6220f839ffa1cabe4070f28d4bb60dab461_000018.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/6fef64a223a2c94c58d0a3d2fcf668878f77c2a1_000032.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/e1c2a12a0376b6986a13f112392990b08e427d31_000026.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/2bfdee5dc71e4bef286b16d36e18ce15452a0cd1_000022.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/c59a28aade80b1279c735f36ffd492f5319494c1_000043.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/2b0ced233dfc45dec6f65f21b562c2afb0994fb1_000025.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/a1f60e6c41a41158ad9d2c5eb15a6cf5b568b251_000044.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/80f17f73516a7850bf485066cc36244d7e54cf71_000001.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/2bfdee5dc71e4bef286b16d36e18ce15452a0cd1_000010.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/c59a28aade80b1279c735f36ffd492f5319494c1_000025.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/ecd22b5d88fda7e9205edb25029715bc57912111_000006.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/7ac6748fd02a8b94093ec1b14208ba8b3991d4e1_000016.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/f68957a7f37b48c8be01c5ee376f90087a556651_000022.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/c59a28aade80b1279c735f36ffd492f5319494c1_000059.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/a7ef648d91554e6062e7f54aabc49295ad3c3151_000048.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/2bfdee5dc71e4bef286b16d36e18ce15452a0cd1_000021.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/cc43bc53bdfc51b2c6eaafbceb243c9fc7589f41_000012.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/54719a08f5de4923119ce8d45130e8b432ba9991_000027.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/456a05720842622e0f24b6b91ae54db658d68ff1_000006.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/275cef85bae4ec4c2b0c2af08f5684fdb32f2b91_000009.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/cc43bc53bdfc51b2c6eaafbceb243c9fc7589f41_000047.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/2bfdee5dc71e4bef286b16d36e18ce15452a0cd1_000004.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/456a05720842622e0f24b6b91ae54db658d68ff1_000032.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/23b66e8d5110fab9ba929912e5572565bc792a41_000034.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/4c597ad130a6a5cc31762cb16684005d72ac66f1_000017.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/2bfdee5dc71e4bef286b16d36e18ce15452a0cd1_000006.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/0e7eed018a0b5d5cf3a1e8d75ec7087b185c13b1_000026.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/23b66e8d5110fab9ba929912e5572565bc792a41_000038.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/f0e93fbb7abf06617ea7733d9b24cd8b20f4f2b1_000025.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/102e487069312295eef00ec2408ad1f00dd4d1e1_000018.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/cc43bc53bdfc51b2c6eaafbceb243c9fc7589f41_000020.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/ecd22b5d88fda7e9205edb25029715bc57912111_000053.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/7ac6748fd02a8b94093ec1b14208ba8b3991d4e1_000011.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/c02636eb173d9b05c994a98e3ed77fb495baf8e1_000010.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/c59a28aade80b1279c735f36ffd492f5319494c1_000027.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/e9dcd6220f839ffa1cabe4070f28d4bb60dab461_000014.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/LAVideo_31_000027.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/c59a28aade80b1279c735f36ffd492f5319494c1_000026.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/e50240dbe29a9d16caed5e8188f62215567fc9b1_000042.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/643768eefe4858227df1e62feec1e16557ad82e1_000009.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/d02209eb8c4fbe6350100e7afae33c3fac7f4fc1_000051.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/e7112c64433c2b55c7638c6455fd0ceff31139f1_000003.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/275cef85bae4ec4c2b0c2af08f5684fdb32f2b91_000014.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/a1f60e6c41a41158ad9d2c5eb15a6cf5b568b251_000036.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/cc43bc53bdfc51b2c6eaafbceb243c9fc7589f41_000023.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/275cef85bae4ec4c2b0c2af08f5684fdb32f2b91_000057.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/94acc9f52dc1cc2d864bc3289eca5f37496d6c41_000006.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/d02209eb8c4fbe6350100e7afae33c3fac7f4fc1_000035.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/8b7006f219a6608b100190d77760c6a48dad7031_000021.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/e9dcd6220f839ffa1cabe4070f28d4bb60dab461_000041.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/b85d17236d94f92c430a2125f8ce2eecfa2b2de1_000026.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/c02636eb173d9b05c994a98e3ed77fb495baf8e1_000034.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/d53fa923ba5f5d830da38c20c624d93f026bcd71_000014.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/fe9c02e3b4943f61e9940313989007653c31fdc1_000004.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/e8b51f33b7d38c96f51a97651db0ed2677861cf1_000010.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/fe9c02e3b4943f61e9940313989007653c31fdc1_000033.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/fe9c02e3b4943f61e9940313989007653c31fdc1_000018.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/e8b51f33b7d38c96f51a97651db0ed2677861cf1_000026.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/23b66e8d5110fab9ba929912e5572565bc792a41_000009.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/a1f60e6c41a41158ad9d2c5eb15a6cf5b568b251_000055.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/456a05720842622e0f24b6b91ae54db658d68ff1_000044.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/ecd22b5d88fda7e9205edb25029715bc57912111_000022.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/e8b51f33b7d38c96f51a97651db0ed2677861cf1_000051.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/0e7eed018a0b5d5cf3a1e8d75ec7087b185c13b1_000010.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/2b0ced233dfc45dec6f65f21b562c2afb0994fb1_000001.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/LAVideo_31_000028.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/ad1e5fa1cd3a77126031374f2f335b99669110b1_000028.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/456a05720842622e0f24b6b91ae54db658d68ff1_000048.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/2bfdee5dc71e4bef286b16d36e18ce15452a0cd1_000043.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/c02636eb173d9b05c994a98e3ed77fb495baf8e1_000026.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/6fef64a223a2c94c58d0a3d2fcf668878f77c2a1_000009.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/e50240dbe29a9d16caed5e8188f62215567fc9b1_000022.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/e50240dbe29a9d16caed5e8188f62215567fc9b1_000021.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/e1c2a12a0376b6986a13f112392990b08e427d31_000011.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/80f17f73516a7850bf485066cc36244d7e54cf71_000005.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/fe9c02e3b4943f61e9940313989007653c31fdc1_000008.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/2bfdee5dc71e4bef286b16d36e18ce15452a0cd1_000032.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/8b7006f219a6608b100190d77760c6a48dad7031_000040.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/6fef64a223a2c94c58d0a3d2fcf668878f77c2a1_000027.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/94acc9f52dc1cc2d864bc3289eca5f37496d6c41_000034.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/4c597ad130a6a5cc31762cb16684005d72ac66f1_000005.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/e8b51f33b7d38c96f51a97651db0ed2677861cf1_000001.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/427eefa6c6e977bed410772f4e622bd88b1a48b1_000008.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/e9dcd6220f839ffa1cabe4070f28d4bb60dab461_000015.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/5e5a642a3d46ff14e5229521cca5b9342da28331_000040.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/80f17f73516a7850bf485066cc36244d7e54cf71_000040.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/102e487069312295eef00ec2408ad1f00dd4d1e1_000046.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/a1f60e6c41a41158ad9d2c5eb15a6cf5b568b251_000035.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/d02209eb8c4fbe6350100e7afae33c3fac7f4fc1_000052.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/da53b257be8e6f02d768a103e375aa972c065661_000058.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/c59a28aade80b1279c735f36ffd492f5319494c1_000044.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/2b0ced233dfc45dec6f65f21b562c2afb0994fb1_000008.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/d02209eb8c4fbe6350100e7afae33c3fac7f4fc1_000037.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/54719a08f5de4923119ce8d45130e8b432ba9991_000025.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/2b0ced233dfc45dec6f65f21b562c2afb0994fb1_000028.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/e8b51f33b7d38c96f51a97651db0ed2677861cf1_000030.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/643768eefe4858227df1e62feec1e16557ad82e1_000023.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/6fef64a223a2c94c58d0a3d2fcf668878f77c2a1_000044.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/275cef85bae4ec4c2b0c2af08f5684fdb32f2b91_000051.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/d02209eb8c4fbe6350100e7afae33c3fac7f4fc1_000013.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/94acc9f52dc1cc2d864bc3289eca5f37496d6c41_000012.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/9b9d5e46770915da30d22040e2c8bcaccc3c8f61_000032.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/643768eefe4858227df1e62feec1e16557ad82e1_000043.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/ecd22b5d88fda7e9205edb25029715bc57912111_000027.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/a1f60e6c41a41158ad9d2c5eb15a6cf5b568b251_000014.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/427eefa6c6e977bed410772f4e622bd88b1a48b1_000037.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/b85d17236d94f92c430a2125f8ce2eecfa2b2de1_000011.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/4c597ad130a6a5cc31762cb16684005d72ac66f1_000009.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/LAVideo_31_000014.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/e7112c64433c2b55c7638c6455fd0ceff31139f1_000006.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/4c597ad130a6a5cc31762cb16684005d72ac66f1_000052.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/9b9d5e46770915da30d22040e2c8bcaccc3c8f61_000058.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/102e487069312295eef00ec2408ad1f00dd4d1e1_000008.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/ecd22b5d88fda7e9205edb25029715bc57912111_000028.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/456a05720842622e0f24b6b91ae54db658d68ff1_000013.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/da53b257be8e6f02d768a103e375aa972c065661_000021.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/275cef85bae4ec4c2b0c2af08f5684fdb32f2b91_000027.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/d02209eb8c4fbe6350100e7afae33c3fac7f4fc1_000016.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/a1f60e6c41a41158ad9d2c5eb15a6cf5b568b251_000024.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/f68957a7f37b48c8be01c5ee376f90087a556651_000037.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/a1f60e6c41a41158ad9d2c5eb15a6cf5b568b251_000032.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/23b66e8d5110fab9ba929912e5572565bc792a41_000018.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/643768eefe4858227df1e62feec1e16557ad82e1_000002.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/040df373aac5e68f071f3c33c3d8e5b31c28a6e1_000050.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/d02209eb8c4fbe6350100e7afae33c3fac7f4fc1_000001.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/275cef85bae4ec4c2b0c2af08f5684fdb32f2b91_000001.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/5e5a642a3d46ff14e5229521cca5b9342da28331_000010.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/b85d17236d94f92c430a2125f8ce2eecfa2b2de1_000035.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/f0e93fbb7abf06617ea7733d9b24cd8b20f4f2b1_000054.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/e1c2a12a0376b6986a13f112392990b08e427d31_000055.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/0e7eed018a0b5d5cf3a1e8d75ec7087b185c13b1_000036.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/ad1e5fa1cd3a77126031374f2f335b99669110b1_000011.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/54719a08f5de4923119ce8d45130e8b432ba9991_000034.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/da53b257be8e6f02d768a103e375aa972c065661_000024.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/9b9d5e46770915da30d22040e2c8bcaccc3c8f61_000038.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/c02636eb173d9b05c994a98e3ed77fb495baf8e1_000013.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/2bfdee5dc71e4bef286b16d36e18ce15452a0cd1_000016.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/c02636eb173d9b05c994a98e3ed77fb495baf8e1_000050.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/e50240dbe29a9d16caed5e8188f62215567fc9b1_000048.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/643768eefe4858227df1e62feec1e16557ad82e1_000001.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/54719a08f5de4923119ce8d45130e8b432ba9991_000050.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/275cef85bae4ec4c2b0c2af08f5684fdb32f2b91_000056.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/e8b51f33b7d38c96f51a97651db0ed2677861cf1_000052.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/e1c2a12a0376b6986a13f112392990b08e427d31_000049.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/54835f75ef6511ed406248262ece47976984a551_000004.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/e8b51f33b7d38c96f51a97651db0ed2677861cf1_000015.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/427eefa6c6e977bed410772f4e622bd88b1a48b1_000057.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/5e5a642a3d46ff14e5229521cca5b9342da28331_000053.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/ad1e5fa1cd3a77126031374f2f335b99669110b1_000034.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/23b66e8d5110fab9ba929912e5572565bc792a41_000053.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/427eefa6c6e977bed410772f4e622bd88b1a48b1_000035.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/da53b257be8e6f02d768a103e375aa972c065661_000055.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/7ac6748fd02a8b94093ec1b14208ba8b3991d4e1_000036.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/LAVideo_31_000006.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/d53fa923ba5f5d830da38c20c624d93f026bcd71_000034.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/fe9c02e3b4943f61e9940313989007653c31fdc1_000028.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/4c597ad130a6a5cc31762cb16684005d72ac66f1_000014.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/456a05720842622e0f24b6b91ae54db658d68ff1_000014.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/c02636eb173d9b05c994a98e3ed77fb495baf8e1_000008.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/456a05720842622e0f24b6b91ae54db658d68ff1_000050.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/2b0ced233dfc45dec6f65f21b562c2afb0994fb1_000010.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/d53fa923ba5f5d830da38c20c624d93f026bcd71_000025.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/da53b257be8e6f02d768a103e375aa972c065661_000013.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/5e5a642a3d46ff14e5229521cca5b9342da28331_000046.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/54719a08f5de4923119ce8d45130e8b432ba9991_000040.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/c02636eb173d9b05c994a98e3ed77fb495baf8e1_000036.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/f68957a7f37b48c8be01c5ee376f90087a556651_000034.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/e1c2a12a0376b6986a13f112392990b08e427d31_000016.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/e8b51f33b7d38c96f51a97651db0ed2677861cf1_000043.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/0e7eed018a0b5d5cf3a1e8d75ec7087b185c13b1_000025.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/8d15119c70c4d2531d2a523cbfa3dd0772d98e21_000024.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/456a05720842622e0f24b6b91ae54db658d68ff1_000003.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/a7ef648d91554e6062e7f54aabc49295ad3c3151_000057.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/fe9c02e3b4943f61e9940313989007653c31fdc1_000020.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/c02636eb173d9b05c994a98e3ed77fb495baf8e1_000020.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/d53fa923ba5f5d830da38c20c624d93f026bcd71_000012.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/643768eefe4858227df1e62feec1e16557ad82e1_000008.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/ad1e5fa1cd3a77126031374f2f335b99669110b1_000049.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/2b0ced233dfc45dec6f65f21b562c2afb0994fb1_000042.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/b85d17236d94f92c430a2125f8ce2eecfa2b2de1_000030.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/c59a28aade80b1279c735f36ffd492f5319494c1_000053.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/040df373aac5e68f071f3c33c3d8e5b31c28a6e1_000033.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/2bfdee5dc71e4bef286b16d36e18ce15452a0cd1_000052.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/102e487069312295eef00ec2408ad1f00dd4d1e1_000058.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/f68957a7f37b48c8be01c5ee376f90087a556651_000015.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/040df373aac5e68f071f3c33c3d8e5b31c28a6e1_000053.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/4c597ad130a6a5cc31762cb16684005d72ac66f1_000030.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/fe9c02e3b4943f61e9940313989007653c31fdc1_000019.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/0e7eed018a0b5d5cf3a1e8d75ec7087b185c13b1_000040.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/d53fa923ba5f5d830da38c20c624d93f026bcd71_000055.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/275cef85bae4ec4c2b0c2af08f5684fdb32f2b91_000040.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/80f17f73516a7850bf485066cc36244d7e54cf71_000027.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/f68957a7f37b48c8be01c5ee376f90087a556651_000023.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/d53fa923ba5f5d830da38c20c624d93f026bcd71_000027.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/80f17f73516a7850bf485066cc36244d7e54cf71_000042.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/275cef85bae4ec4c2b0c2af08f5684fdb32f2b91_000043.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/f0e93fbb7abf06617ea7733d9b24cd8b20f4f2b1_000021.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/0e7eed018a0b5d5cf3a1e8d75ec7087b185c13b1_000005.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/fe9c02e3b4943f61e9940313989007653c31fdc1_000040.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/e9dcd6220f839ffa1cabe4070f28d4bb60dab461_000048.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/b85d17236d94f92c430a2125f8ce2eecfa2b2de1_000037.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/102e487069312295eef00ec2408ad1f00dd4d1e1_000028.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/23b66e8d5110fab9ba929912e5572565bc792a41_000035.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/e1c2a12a0376b6986a13f112392990b08e427d31_000023.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/9b9d5e46770915da30d22040e2c8bcaccc3c8f61_000034.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/4c597ad130a6a5cc31762cb16684005d72ac66f1_000041.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/2b0ced233dfc45dec6f65f21b562c2afb0994fb1_000058.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/54719a08f5de4923119ce8d45130e8b432ba9991_000058.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/2bfdee5dc71e4bef286b16d36e18ce15452a0cd1_000011.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/54835f75ef6511ed406248262ece47976984a551_000008.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/da53b257be8e6f02d768a103e375aa972c065661_000057.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/6fef64a223a2c94c58d0a3d2fcf668878f77c2a1_000059.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/cc43bc53bdfc51b2c6eaafbceb243c9fc7589f41_000022.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/e9dcd6220f839ffa1cabe4070f28d4bb60dab461_000052.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/54719a08f5de4923119ce8d45130e8b432ba9991_000018.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/7ac6748fd02a8b94093ec1b14208ba8b3991d4e1_000047.jpg\n/kaggle/input/netra-jpeg/JPEGImages_200/275cef85bae4ec4c2b0c2af08f5684fdb32f2b91_000026.jpg\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# Clone the YOLOv5 repository\n!git clone https://github.com/ultralytics/yolov5","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T06:19:43.698998Z","iopub.execute_input":"2025-07-17T06:19:43.699452Z","iopub.status.idle":"2025-07-17T06:19:46.249744Z","shell.execute_reply.started":"2025-07-17T06:19:43.699417Z","shell.execute_reply":"2025-07-17T06:19:46.249056Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'yolov5'...\nremote: Enumerating objects: 17516, done.\u001b[K\nremote: Counting objects: 100% (19/19), done.\u001b[K\nremote: Compressing objects: 100% (19/19), done.\u001b[K\nremote: Total 17516 (delta 6), reused 0 (delta 0), pack-reused 17497 (from 4)\u001b[K\nReceiving objects: 100% (17516/17516), 16.62 MiB | 20.71 MiB/s, done.\nResolving deltas: 100% (12001/12001), done.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"cd /kaggle/working/yolov5","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T06:19:47.639800Z","iopub.execute_input":"2025-07-17T06:19:47.640050Z","iopub.status.idle":"2025-07-17T06:19:47.646478Z","shell.execute_reply.started":"2025-07-17T06:19:47.640027Z","shell.execute_reply":"2025-07-17T06:19:47.645915Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/yolov5\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"!pip install -r requirements.txt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T06:19:49.123349Z","iopub.execute_input":"2025-07-17T06:19:49.123591Z","iopub.status.idle":"2025-07-17T06:22:02.736828Z","shell.execute_reply.started":"2025-07-17T06:19:49.123573Z","shell.execute_reply":"2025-07-17T06:22:02.736120Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: gitpython>=3.1.30 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (3.1.44)\nRequirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (3.7.2)\nRequirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (1.26.4)\nRequirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (4.11.0.86)\nRequirement already satisfied: pillow>=10.3.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (11.1.0)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (7.0.0)\nRequirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (6.0.2)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 12)) (2.32.3)\nRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (1.15.2)\nCollecting thop>=0.1.1 (from -r requirements.txt (line 14))\n  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\nRequirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 15)) (2.6.0+cu124)\nRequirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 16)) (0.21.0+cu124)\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 17)) (4.67.1)\nCollecting ultralytics>=8.2.64 (from -r requirements.txt (line 18))\n  Downloading ultralytics-8.3.167-py3-none-any.whl.metadata (37 kB)\nRequirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 27)) (2.2.3)\nRequirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 28)) (0.12.2)\nRequirement already satisfied: setuptools>=70.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 42)) (75.2.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython>=3.1.30->-r requirements.txt (line 5)) (4.0.12)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (4.57.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (25.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.5->-r requirements.txt (line 7)) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.5->-r requirements.txt (line 7)) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.5->-r requirements.txt (line 7)) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.5->-r requirements.txt (line 7)) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.5->-r requirements.txt (line 7)) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.5->-r requirements.txt (line 7)) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (2025.4.26)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (4.13.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->-r requirements.txt (line 15))\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->-r requirements.txt (line 15))\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->-r requirements.txt (line 15))\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->-r requirements.txt (line 15))\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->-r requirements.txt (line 15))\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->-r requirements.txt (line 15))\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->-r requirements.txt (line 15))\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->-r requirements.txt (line 15)) (1.3.0)\nRequirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics>=8.2.64->-r requirements.txt (line 18)) (9.0.0)\nCollecting ultralytics-thop>=2.0.0 (from ultralytics>=8.2.64->-r requirements.txt (line 18))\n  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2025.2)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r requirements.txt (line 5)) (5.0.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3->-r requirements.txt (line 6)) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->-r requirements.txt (line 15)) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.5->-r requirements.txt (line 7)) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.5->-r requirements.txt (line 7)) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.23.5->-r requirements.txt (line 7)) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.23.5->-r requirements.txt (line 7)) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.23.5->-r requirements.txt (line 7)) (2024.2.0)\nDownloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading ultralytics-8.3.167-py3-none-any.whl (1.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\nInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, thop, ultralytics-thop, ultralytics\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.9.41\n    Uninstalling nvidia-nvjitlink-cu12-12.9.41:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.41\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.10.19\n    Uninstalling nvidia-curand-cu12-10.3.10.19:\n      Successfully uninstalled nvidia-curand-cu12-10.3.10.19\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.4.0.6\n    Uninstalling nvidia-cufft-cu12-11.4.0.6:\n      Successfully uninstalled nvidia-cufft-cu12-11.4.0.6\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.9.0.13\n    Uninstalling nvidia-cublas-cu12-12.9.0.13:\n      Successfully uninstalled nvidia-cublas-cu12-12.9.0.13\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.9.5\n    Uninstalling nvidia-cusparse-cu12-12.5.9.5:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.9.5\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.4.40\n    Uninstalling nvidia-cusolver-cu12-11.7.4.40:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.4.40\nSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 thop-0.1.1.post2209072238 ultralytics-8.3.167 ultralytics-thop-2.0.14\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"!pip install aimet-torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T06:22:32.833692Z","iopub.execute_input":"2025-07-17T06:22:32.834531Z","iopub.status.idle":"2025-07-17T06:22:41.110197Z","shell.execute_reply.started":"2025-07-17T06:22:32.834498Z","shell.execute_reply":"2025-07-17T06:22:41.109463Z"}},"outputs":[{"name":"stdout","text":"Collecting aimet-torch\n  Downloading aimet_torch-2.10.0-py38-none-any.whl.metadata (11 kB)\nRequirement already satisfied: Jinja2>=3.0.3 in /usr/local/lib/python3.11/dist-packages (from aimet-torch) (3.1.6)\nRequirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from aimet-torch) (6.0.2)\nRequirement already satisfied: bokeh<=3.6.3 in /usr/local/lib/python3.11/dist-packages (from aimet-torch) (3.6.3)\nRequirement already satisfied: cvxpy in /usr/local/lib/python3.11/dist-packages (from aimet-torch) (1.6.4)\nRequirement already satisfied: holoviews in /usr/local/lib/python3.11/dist-packages (from aimet-torch) (1.20.2)\nCollecting hvplot (from aimet-torch)\n  Downloading hvplot-0.11.3-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from aimet-torch) (4.23.0)\nRequirement already satisfied: matplotlib>=3 in /usr/local/lib/python3.11/dist-packages (from aimet-torch) (3.7.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from aimet-torch) (3.4.2)\nRequirement already satisfied: numpy<2 in /usr/local/lib/python3.11/dist-packages (from aimet-torch) (1.26.4)\nRequirement already satisfied: onnx in /usr/local/lib/python3.11/dist-packages (from aimet-torch) (1.17.0)\nCollecting onnxscript>=0.2.0 (from aimet-torch)\n  Downloading onnxscript-0.3.2-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: osqp in /usr/local/lib/python3.11/dist-packages (from aimet-torch) (1.0.3)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from aimet-torch) (2.2.3)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from aimet-torch) (7.0.0)\nRequirement already satisfied: pybind11 in /usr/local/lib/python3.11/dist-packages (from aimet-torch) (2.13.6)\nRequirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from aimet-torch) (0.5.3)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from aimet-torch) (1.2.2)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from aimet-torch) (1.15.2)\nRequirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (from aimet-torch) (2.18.0)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from aimet-torch) (2.6.0+cu124)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from aimet-torch) (0.21.0+cu124)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from aimet-torch) (4.67.1)\nRequirement already satisfied: contourpy>=1.2 in /usr/local/lib/python3.11/dist-packages (from bokeh<=3.6.3->aimet-torch) (1.3.1)\nRequirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.11/dist-packages (from bokeh<=3.6.3->aimet-torch) (25.0)\nRequirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from bokeh<=3.6.3->aimet-torch) (11.1.0)\nRequirement already satisfied: tornado>=6.2 in /usr/local/lib/python3.11/dist-packages (from bokeh<=3.6.3->aimet-torch) (6.4.2)\nRequirement already satisfied: xyzservices>=2021.09.1 in /usr/local/lib/python3.11/dist-packages (from bokeh<=3.6.3->aimet-torch) (2025.1.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.0.3->aimet-torch) (3.0.2)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3->aimet-torch) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3->aimet-torch) (4.57.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3->aimet-torch) (1.4.8)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3->aimet-torch) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3->aimet-torch) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2->aimet-torch) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2->aimet-torch) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2->aimet-torch) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2->aimet-torch) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2->aimet-torch) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2->aimet-torch) (2.4.1)\nRequirement already satisfied: ml_dtypes in /usr/local/lib/python3.11/dist-packages (from onnxscript>=0.2.0->aimet-torch) (0.4.1)\nCollecting onnx_ir<2,>=0.1.3 (from onnxscript>=0.2.0->aimet-torch)\n  Downloading onnx_ir-0.1.4-py3-none-any.whl.metadata (4.8 kB)\nRequirement already satisfied: typing_extensions>=4.10 in /usr/local/lib/python3.11/dist-packages (from onnxscript>=0.2.0->aimet-torch) (4.13.2)\nRequirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from onnx->aimet-torch) (3.20.3)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->aimet-torch) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->aimet-torch) (2025.2)\nRequirement already satisfied: clarabel>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from cvxpy->aimet-torch) (0.10.0)\nRequirement already satisfied: scs>=3.2.4.post1 in /usr/local/lib/python3.11/dist-packages (from cvxpy->aimet-torch) (3.2.7.post2)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from osqp->aimet-torch) (75.2.0)\nRequirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from osqp->aimet-torch) (1.5.0)\nRequirement already satisfied: colorcet in /usr/local/lib/python3.11/dist-packages (from holoviews->aimet-torch) (3.1.0)\nRequirement already satisfied: panel>=1.0 in /usr/local/lib/python3.11/dist-packages (from holoviews->aimet-torch) (1.6.2)\nRequirement already satisfied: param<3.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from holoviews->aimet-torch) (2.2.0)\nRequirement already satisfied: pyviz-comms>=2.1 in /usr/local/lib/python3.11/dist-packages (from holoviews->aimet-torch) (3.0.4)\nRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema->aimet-torch) (25.3.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->aimet-torch) (2024.10.1)\nRequirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema->aimet-torch) (0.36.2)\nRequirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->aimet-torch) (0.24.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->aimet-torch) (3.6.0)\nRequirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard->aimet-torch) (1.4.0)\nRequirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard->aimet-torch) (1.72.0rc1)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard->aimet-torch) (3.7)\nRequirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard->aimet-torch) (1.17.0)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->aimet-torch) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard->aimet-torch) (3.1.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->aimet-torch) (3.18.0)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->aimet-torch) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->aimet-torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->aimet-torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->aimet-torch) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->aimet-torch) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->aimet-torch) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->aimet-torch) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->aimet-torch) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->aimet-torch) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->aimet-torch) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->aimet-torch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->aimet-torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->aimet-torch) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->aimet-torch) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->aimet-torch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->aimet-torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->aimet-torch) (1.3.0)\nRequirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from panel>=1.0->holoviews->aimet-torch) (6.2.0)\nRequirement already satisfied: linkify-it-py in /usr/local/lib/python3.11/dist-packages (from panel>=1.0->holoviews->aimet-torch) (2.0.3)\nRequirement already satisfied: markdown-it-py in /usr/local/lib/python3.11/dist-packages (from panel>=1.0->holoviews->aimet-torch) (3.0.0)\nRequirement already satisfied: mdit-py-plugins in /usr/local/lib/python3.11/dist-packages (from panel>=1.0->holoviews->aimet-torch) (0.4.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from panel>=1.0->holoviews->aimet-torch) (2.32.3)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2->aimet-torch) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2->aimet-torch) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2->aimet-torch) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2->aimet-torch) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2->aimet-torch) (2024.2.0)\nRequirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach->panel>=1.0->holoviews->aimet-torch) (0.5.1)\nRequirement already satisfied: uc-micro-py in /usr/local/lib/python3.11/dist-packages (from linkify-it-py->panel>=1.0->holoviews->aimet-torch) (1.0.3)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py->panel>=1.0->holoviews->aimet-torch) (0.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->panel>=1.0->holoviews->aimet-torch) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->panel>=1.0->holoviews->aimet-torch) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->panel>=1.0->holoviews->aimet-torch) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->panel>=1.0->holoviews->aimet-torch) (2025.4.26)\nDownloading aimet_torch-2.10.0-py38-none-any.whl (9.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading onnxscript-0.3.2-py3-none-any.whl (667 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m667.4/667.4 kB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading hvplot-0.11.3-py3-none-any.whl (170 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.3/170.3 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading onnx_ir-0.1.4-py3-none-any.whl (118 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.0/119.0 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: onnx_ir, onnxscript, hvplot, aimet-torch\nSuccessfully installed aimet-torch-2.10.0 hvplot-0.11.3 onnx_ir-0.1.4 onnxscript-0.3.2\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import torch\nfrom aimet_torch.quantsim import QuantizationSimModel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T06:22:43.644567Z","iopub.execute_input":"2025-07-17T06:22:43.644822Z","iopub.status.idle":"2025-07-17T06:23:11.846369Z","shell.execute_reply.started":"2025-07-17T06:22:43.644797Z","shell.execute_reply":"2025-07-17T06:23:11.845480Z"}},"outputs":[{"name":"stderr","text":"<frozen abc>:106: FutureWarning: `NLLLoss2d` has been deprecated. Please use `NLLLoss` instead as a drop-in replacement and see https://pytorch.org/docs/main/nn.html#torch.nn.NLLLoss for more details.\n2025-07-17 06:22:59.683677: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1752733379.869124      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1752733379.925415      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n<frozen abc>:106: FutureWarning: `NLLLoss2d` has been deprecated. Please use `NLLLoss` instead as a drop-in replacement and see https://pytorch.org/docs/main/nn.html#torch.nn.NLLLoss for more details.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"weights_path = \"/kaggle/input/netra_dyne/pytorch/default/1/best 1.pt\"\n\nimgsz = 640\nbatch_size = 32","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T06:25:59.338578Z","iopub.execute_input":"2025-07-17T06:25:59.339240Z","iopub.status.idle":"2025-07-17T06:25:59.343114Z","shell.execute_reply.started":"2025-07-17T06:25:59.339218Z","shell.execute_reply":"2025-07-17T06:25:59.342219Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"from models.experimental import attempt_load","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T06:26:00.742556Z","iopub.execute_input":"2025-07-17T06:26:00.742838Z","iopub.status.idle":"2025-07-17T06:26:00.746722Z","shell.execute_reply.started":"2025-07-17T06:26:00.742817Z","shell.execute_reply":"2025-07-17T06:26:00.745927Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"model = attempt_load(weights_path).eval()  # YOLOv5s","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T06:26:01.780924Z","iopub.execute_input":"2025-07-17T06:26:01.781231Z","iopub.status.idle":"2025-07-17T06:26:01.992500Z","shell.execute_reply.started":"2025-07-17T06:26:01.781210Z","shell.execute_reply":"2025-07-17T06:26:01.991625Z"}},"outputs":[{"name":"stderr","text":"Fusing layers... \nYOLOv5s summary: 157 layers, 7047883 parameters, 0 gradients, 15.9 GFLOPs\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom pathlib import Path\nfrom PIL import Image\nimport torchvision.transforms as T\n\nclass ImageFolderSimple(Dataset):\n    def __init__(self, image_dir, img_size=640):\n        self.image_paths = list(Path(image_dir).glob(\"*.jpg\"))\n        self.transform = T.Compose([\n            T.Resize((img_size, img_size)),\n            T.ToTensor(),  # Converts to [0,1]\n        ])\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        img_path = self.image_paths[idx]\n        image = Image.open(img_path).convert(\"RGB\")\n        return self.transform(image)\n\n# Create loader\nval_dataset = ImageFolderSimple(\"/kaggle/input/netra-1000/1000_jpg_images\", img_size=640)\nval_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, num_workers=2)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T06:23:31.298599Z","iopub.execute_input":"2025-07-17T06:23:31.299546Z","iopub.status.idle":"2025-07-17T06:23:31.310989Z","shell.execute_reply.started":"2025-07-17T06:23:31.299521Z","shell.execute_reply":"2025-07-17T06:23:31.310391Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"from aimet_torch.quantsim import QuantizationSimModel\nfrom aimet_torch.batch_norm_fold import fold_all_batch_norms\nfrom aimet_common.defs import QuantScheme\nfrom aimet_common.quantsim_config.utils import get_path_for_per_channel_config\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T06:23:33.705209Z","iopub.execute_input":"2025-07-17T06:23:33.705905Z","iopub.status.idle":"2025-07-17T06:23:33.713413Z","shell.execute_reply.started":"2025-07-17T06:23:33.705880Z","shell.execute_reply":"2025-07-17T06:23:33.712643Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"dummy_input = torch.randn(1, 3, imgsz, imgsz)  # float32 dummy input\nmodel.fuse() # batch norm folding","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T06:26:39.891159Z","iopub.execute_input":"2025-07-17T06:26:39.891737Z","iopub.status.idle":"2025-07-17T06:26:39.957149Z","shell.execute_reply.started":"2025-07-17T06:26:39.891716Z","shell.execute_reply":"2025-07-17T06:26:39.956465Z"}},"outputs":[{"name":"stderr","text":"Fusing layers... \nYOLOv5s summary: 157 layers, 7047883 parameters, 0 gradients, 15.9 GFLOPs\n","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"DetectionModel(\n  (model): Sequential(\n    (0): Conv(\n      (conv): Conv2d(3, 32, kernel_size=(6, 6), stride=(2, 2), padding=(2, 2))\n      (act): SiLU(inplace=True)\n    )\n    (1): Conv(\n      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n      (act): SiLU(inplace=True)\n    )\n    (2): C3(\n      (cv1): Conv(\n        (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n        (act): SiLU(inplace=True)\n      )\n      (cv2): Conv(\n        (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n        (act): SiLU(inplace=True)\n      )\n      (cv3): Conv(\n        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n        (act): SiLU(inplace=True)\n      )\n      (m): Sequential(\n        (0): Bottleneck(\n          (cv1): Conv(\n            (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n            (act): SiLU(inplace=True)\n          )\n          (cv2): Conv(\n            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (act): SiLU(inplace=True)\n          )\n        )\n      )\n    )\n    (3): Conv(\n      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n      (act): SiLU(inplace=True)\n    )\n    (4): C3(\n      (cv1): Conv(\n        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n        (act): SiLU(inplace=True)\n      )\n      (cv2): Conv(\n        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n        (act): SiLU(inplace=True)\n      )\n      (cv3): Conv(\n        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n        (act): SiLU(inplace=True)\n      )\n      (m): Sequential(\n        (0): Bottleneck(\n          (cv1): Conv(\n            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n            (act): SiLU(inplace=True)\n          )\n          (cv2): Conv(\n            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (act): SiLU(inplace=True)\n          )\n        )\n        (1): Bottleneck(\n          (cv1): Conv(\n            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n            (act): SiLU(inplace=True)\n          )\n          (cv2): Conv(\n            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (act): SiLU(inplace=True)\n          )\n        )\n      )\n    )\n    (5): Conv(\n      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n      (act): SiLU(inplace=True)\n    )\n    (6): C3(\n      (cv1): Conv(\n        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n        (act): SiLU(inplace=True)\n      )\n      (cv2): Conv(\n        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n        (act): SiLU(inplace=True)\n      )\n      (cv3): Conv(\n        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n        (act): SiLU(inplace=True)\n      )\n      (m): Sequential(\n        (0): Bottleneck(\n          (cv1): Conv(\n            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n            (act): SiLU(inplace=True)\n          )\n          (cv2): Conv(\n            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (act): SiLU(inplace=True)\n          )\n        )\n        (1): Bottleneck(\n          (cv1): Conv(\n            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n            (act): SiLU(inplace=True)\n          )\n          (cv2): Conv(\n            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (act): SiLU(inplace=True)\n          )\n        )\n        (2): Bottleneck(\n          (cv1): Conv(\n            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n            (act): SiLU(inplace=True)\n          )\n          (cv2): Conv(\n            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (act): SiLU(inplace=True)\n          )\n        )\n      )\n    )\n    (7): Conv(\n      (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n      (act): SiLU(inplace=True)\n    )\n    (8): C3(\n      (cv1): Conv(\n        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n        (act): SiLU(inplace=True)\n      )\n      (cv2): Conv(\n        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n        (act): SiLU(inplace=True)\n      )\n      (cv3): Conv(\n        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n        (act): SiLU(inplace=True)\n      )\n      (m): Sequential(\n        (0): Bottleneck(\n          (cv1): Conv(\n            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n            (act): SiLU(inplace=True)\n          )\n          (cv2): Conv(\n            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (act): SiLU(inplace=True)\n          )\n        )\n      )\n    )\n    (9): SPPF(\n      (cv1): Conv(\n        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n        (act): SiLU(inplace=True)\n      )\n      (cv2): Conv(\n        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n        (act): SiLU(inplace=True)\n      )\n      (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n    )\n    (10): Conv(\n      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n      (act): SiLU(inplace=True)\n    )\n    (11): Upsample(scale_factor=2.0, mode='nearest')\n    (12): Concat()\n    (13): C3(\n      (cv1): Conv(\n        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n        (act): SiLU(inplace=True)\n      )\n      (cv2): Conv(\n        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n        (act): SiLU(inplace=True)\n      )\n      (cv3): Conv(\n        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n        (act): SiLU(inplace=True)\n      )\n      (m): Sequential(\n        (0): Bottleneck(\n          (cv1): Conv(\n            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n            (act): SiLU(inplace=True)\n          )\n          (cv2): Conv(\n            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (act): SiLU(inplace=True)\n          )\n        )\n      )\n    )\n    (14): Conv(\n      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n      (act): SiLU(inplace=True)\n    )\n    (15): Upsample(scale_factor=2.0, mode='nearest')\n    (16): Concat()\n    (17): C3(\n      (cv1): Conv(\n        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n        (act): SiLU(inplace=True)\n      )\n      (cv2): Conv(\n        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n        (act): SiLU(inplace=True)\n      )\n      (cv3): Conv(\n        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n        (act): SiLU(inplace=True)\n      )\n      (m): Sequential(\n        (0): Bottleneck(\n          (cv1): Conv(\n            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n            (act): SiLU(inplace=True)\n          )\n          (cv2): Conv(\n            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (act): SiLU(inplace=True)\n          )\n        )\n      )\n    )\n    (18): Conv(\n      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n      (act): SiLU(inplace=True)\n    )\n    (19): Concat()\n    (20): C3(\n      (cv1): Conv(\n        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n        (act): SiLU(inplace=True)\n      )\n      (cv2): Conv(\n        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n        (act): SiLU(inplace=True)\n      )\n      (cv3): Conv(\n        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n        (act): SiLU(inplace=True)\n      )\n      (m): Sequential(\n        (0): Bottleneck(\n          (cv1): Conv(\n            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n            (act): SiLU(inplace=True)\n          )\n          (cv2): Conv(\n            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (act): SiLU(inplace=True)\n          )\n        )\n      )\n    )\n    (21): Conv(\n      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n      (act): SiLU(inplace=True)\n    )\n    (22): Concat()\n    (23): C3(\n      (cv1): Conv(\n        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n        (act): SiLU(inplace=True)\n      )\n      (cv2): Conv(\n        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n        (act): SiLU(inplace=True)\n      )\n      (cv3): Conv(\n        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n        (act): SiLU(inplace=True)\n      )\n      (m): Sequential(\n        (0): Bottleneck(\n          (cv1): Conv(\n            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n            (act): SiLU(inplace=True)\n          )\n          (cv2): Conv(\n            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            (act): SiLU(inplace=True)\n          )\n        )\n      )\n    )\n    (24): Detect(\n      (m): ModuleList(\n        (0): Conv2d(128, 57, kernel_size=(1, 1), stride=(1, 1))\n        (1): Conv2d(256, 57, kernel_size=(1, 1), stride=(1, 1))\n        (2): Conv2d(512, 57, kernel_size=(1, 1), stride=(1, 1))\n      )\n    )\n  )\n)"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"from aimet_torch.v2.nn import QuantizationMixin\nfrom models.common import Concat  # This is YOLOv5's Concat module\n\n@QuantizationMixin.implements(Concat)\nclass QuantizedConcat(QuantizationMixin, Concat):\n    def __quant_init__(self):\n        super().__quant_init__()\n        self.input_quantizers = torch.nn.ModuleList([None])  # 1 input\n        self.output_quantizers = torch.nn.ModuleList([None])  # 1 output\n\n    def forward(self, x):\n        # Quantize inputs\n        if self.input_quantizers[0]:\n            x = self.input_quantizers[0](x)\n\n        with self._patch_quantized_parameters():\n            out = super().forward(x)\n\n        # Quantize output\n        if self.output_quantizers[0]:\n            out = self.output_quantizers[0](out)\n\n        return out\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T06:28:32.037575Z","iopub.execute_input":"2025-07-17T06:28:32.038145Z","iopub.status.idle":"2025-07-17T06:28:32.043436Z","shell.execute_reply.started":"2025-07-17T06:28:32.038124Z","shell.execute_reply":"2025-07-17T06:28:32.042726Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# Sim model creation\nsim = QuantizationSimModel(\n    model=model,\n    dummy_input=torch.randn(1, 3, imgsz, imgsz),  # must match model input size\n    quant_scheme='tf_enhanced',\n    rounding_mode='nearest',\n    config_file=get_path_for_per_channel_config(),\n    default_output_bw=8,\n    default_param_bw=8\n)\n\n#sim.exclude_layers(['model.12', 'model.16', 'model.19', 'model.22'])\n\n# --- CALIBRATION (compute encodings) ---\ndef calibration_forward_pass(model, _):\n    model.eval()\n    with torch.no_grad():\n        for i, img in enumerate(val_loader):\n            img = img.float() / 255.0  # Optional if already in [0,1] from ToTensor\n            model(img)\n\n# Compute quantization encodings (this initializes quant params)\nsim.compute_encodings(calibration_forward_pass, None)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T06:28:41.717481Z","iopub.execute_input":"2025-07-17T06:28:41.718283Z","iopub.status.idle":"2025-07-17T06:57:07.218565Z","shell.execute_reply.started":"2025-07-17T06:28:41.718252Z","shell.execute_reply":"2025-07-17T06:57:07.217672Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_35/2362876525.py:2: DeprecationWarning: \u001b[31;21mPassing rounding_mode='nearest' is no longer needed and will be deprecated soon in the later versions.\u001b[0m\n  sim = QuantizationSimModel(\n/kaggle/working/yolov5/models/yolo.py:101: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n  if self.dynamic or self.grid[i].shape[2:4] != x[i].shape[2:4]:\n/usr/local/lib/python3.11/dist-packages/torch/jit/_trace.py:1276: TracerWarning: Encountering a list at the output of the tracer might cause the trace to be incorrect, this is only valid if the container structure does not change based on the module's inputs. Consider using a constant container instead (e.g. for `list`, use a `tuple` instead. for `dict`, use a `NamedTuple` instead). If you absolutely need this and know the side effects, pass strict=False to trace() to allow this behavior.\n  module._c._create_method_from_trace(\n","output_type":"stream"},{"name":"stdout","text":"2025-07-17 06:28:43,457 - Quant - INFO - Unsupported op type Squeeze\n2025-07-17 06:28:43,458 - Quant - INFO - Unsupported op type Mean\n2025-07-17 06:28:43,459 - Quant - INFO - Unsupported op type Unsqueeze\n2025-07-17 06:28:43,459 - Quant - INFO - Unsupported op type Compress\n2025-07-17 06:28:43,460 - Quant - INFO - Unsupported op type Identity\n2025-07-17 06:28:43,461 - Quant - INFO - Unsupported op type Shape\n2025-07-17 06:28:43,461 - Quant - INFO - Unsupported op type If\n2025-07-17 06:28:43,482 - Quant - INFO - Selecting DefaultOpInstanceConfigGenerator to compute the specialized config. hw_version:None\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"sim.export('./models/', 'netra-1000_tf_advanced', dummy_input=torch.randn(1, 3, imgsz, imgsz))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T06:58:51.056338Z","iopub.execute_input":"2025-07-17T06:58:51.057147Z","iopub.status.idle":"2025-07-17T06:58:56.449659Z","shell.execute_reply.started":"2025-07-17T06:58:51.057114Z","shell.execute_reply":"2025-07-17T06:58:56.449130Z"}},"outputs":[{"name":"stderr","text":"/kaggle/working/yolov5/models/yolo.py:268: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n  if augment:\n/kaggle/working/yolov5/models/yolo.py:167: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n  if profile:\n/kaggle/working/yolov5/models/yolo.py:171: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n  if visualize:\n/kaggle/working/yolov5/models/yolo.py:171: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n  if visualize:\n/kaggle/working/yolov5/models/yolo.py:167: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n  if profile:\n/kaggle/working/yolov5/models/yolo.py:101: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n  if self.dynamic or self.grid[i].shape[2:4] != x[i].shape[2:4]:\n","output_type":"stream"},{"name":"stdout","text":"2025-07-17 06:58:55,805 - Utils - WARNING - end-marker seen without passing start-marker for 'model.12', continue to use parent context '<model>'\n2025-07-17 06:58:55,807 - Utils - WARNING - end-marker seen without passing start-marker for 'model.16', continue to use parent context '<model>'\n2025-07-17 06:58:55,808 - Utils - WARNING - end-marker seen without passing start-marker for 'model.19', continue to use parent context '<model>'\n2025-07-17 06:58:55,809 - Utils - WARNING - end-marker seen without passing start-marker for 'model.22', continue to use parent context '<model>'\n2025-07-17 06:58:55,811 - Utils - WARNING - end-marker seen without passing start-marker for 'model.24', continue to use parent context '<model>'\n2025-07-17 06:58:55,820 - Utils - WARNING - end-marker seen without passing start-marker for 'model.12', continue to use parent context '<model>'\n2025-07-17 06:58:55,821 - Utils - WARNING - end-marker seen without passing start-marker for 'model.16', continue to use parent context '<model>'\n2025-07-17 06:58:55,822 - Utils - WARNING - end-marker seen without passing start-marker for 'model.19', continue to use parent context '<model>'\n2025-07-17 06:58:55,823 - Utils - WARNING - end-marker seen without passing start-marker for 'model.22', continue to use parent context '<model>'\n2025-07-17 06:58:55,824 - Utils - WARNING - end-marker seen without passing start-marker for 'model.24', continue to use parent context '<model>'\n2025-07-17 06:58:55,987 - Utils - INFO - successfully created onnx model with 179/262 node names updated\n2025-07-17 06:58:56,154 - Quant - INFO - layer_name: model.9.m, has multiple output onnx ops: 3,[#0.0.end:1,#0-1.end:1,#0-2.end:1]\n2025-07-17 06:58:56,155 - Quant - WARNING - number of output quantizers: 1 available for layer: model.9.m doesn't match with number of output tensors: 3\n2025-07-17 06:58:56,193 - Quant - WARNING - The following layers were not found in the exported onnx model. Encodings for these layers will not appear in the exported encodings file, however it will continue to exist in torch encoding file:\n['model.12', 'model.16', 'model.19', 'model.22']\nThis can be due to several reasons:\n\t- The layer is set to quantize with float datatype, but was not exercised in compute encodings. Not an issue if the layer is not meant to be run.\n\t- The layer has valid encodings but was not seen while exporting to onnx using the dummy input provided in sim.export(). Ensure that the dummy input covers all layers.\n2025-07-17 06:58:56,194 - Quant - INFO - Layers excluded from quantization: []\n2025-07-17 06:58:56,214 - Quant - WARNING - \u001b[31;21mQuantsim export will stop exporting encodings for saving and loading in a future AIMET release.\nTo export encodings for saving and loading, use QuantizationSimModel's save_encodings_to_json() utility instead.\u001b[0m\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
